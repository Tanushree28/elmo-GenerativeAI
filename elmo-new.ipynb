{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf;\nimport tensorflow_hub as hub\n\nimport spacy\nfrom spacy.lang.en import English\nfrom spacy import displacy\n\n# Load the spaCy model\n# nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Set a larger max_length limit\n# nlp.max_length = 35000000\n# nlp.add_pipe('sentencizer')\n\nimport logging\nlogging.getLogger('tensorflow').disabled = True ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:52:56.956794Z","iopub.execute_input":"2023-08-02T13:52:56.957102Z","iopub.status.idle":"2023-08-02T13:53:16.561095Z","shell.execute_reply.started":"2023-08-02T13:52:56.957075Z","shell.execute_reply":"2023-08-02T13:53:16.560082Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/marvel-dataset/Marvel Datastore.xlsx')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:16.563053Z","iopub.execute_input":"2023-08-02T13:53:16.563787Z","iopub.status.idle":"2023-08-02T13:53:16.984848Z","shell.execute_reply.started":"2023-08-02T13:53:16.563751Z","shell.execute_reply":"2023-08-02T13:53:16.983928Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                         Description\n0  Thor Odinson is the Asgardian God of Thunder, ...\n1  Upon being welcomed back to Asgard as a hero, ...\n2  Thor returned to Asgard having defeated his br...\n3  Loki Laufeyson was the biological son of Laufe...\n4  Transported by the wormhole to Sanctuary, Loki...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thor Odinson is the Asgardian God of Thunder, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Upon being welcomed back to Asgard as a hero, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thor returned to Asgard having defeated his br...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Loki Laufeyson was the biological son of Laufe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Transported by the wormhole to Sanctuary, Loki...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install mteb","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:16.986104Z","iopub.execute_input":"2023-08-02T13:53:16.987081Z","iopub.status.idle":"2023-08-02T13:53:33.487467Z","shell.execute_reply.started":"2023-08-02T13:53:16.987045Z","shell.execute_reply":"2023-08-02T13:53:33.486304Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting mteb\n  Downloading mteb-1.1.0-py3-none-any.whl (102 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting datasets>=2.2.0 (from mteb)\n  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting jsonlines (from mteb)\n  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mteb) (1.23.5)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from mteb) (2.31.0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from mteb) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mteb) (1.11.1)\nCollecting sentence-transformers>=2.2.0 (from mteb)\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mteb) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mteb) (4.65.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mteb) (13.4.2)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb) (6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb) (3.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb) (4.30.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb) (0.15.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb) (0.1.99)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mteb) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->mteb) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mteb) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mteb) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mteb) (3.1.2)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->mteb) (23.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mteb) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mteb) (2.15.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mteb) (0.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.2.0->mteb) (3.0.9)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mteb) (2.1.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.0->mteb) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.2.0->mteb) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.2.0->mteb) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mteb) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.0->mteb) (9.5.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=d015c36cfd18b6288a360e9e9ed34d14f9a78f09d85c405a6da85194252a067f\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: jsonlines, sentence-transformers, datasets, mteb\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.2 jsonlines-3.1.0 mteb-1.1.0 sentence-transformers-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install mteb[beir]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:53:33.490639Z","iopub.execute_input":"2023-08-02T13:53:33.491006Z","iopub.status.idle":"2023-08-02T13:54:01.794059Z","shell.execute_reply.started":"2023-08-02T13:53:33.490969Z","shell.execute_reply":"2023-08-02T13:54:01.792807Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: mteb[beir] in /opt/conda/lib/python3.10/site-packages (1.1.0)\nRequirement already satisfied: datasets>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (2.14.2)\nRequirement already satisfied: jsonlines in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (3.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (1.23.5)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (2.31.0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (1.11.1)\nRequirement already satisfied: sentence-transformers>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (2.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (4.65.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mteb[beir]) (13.4.2)\nCollecting beir (from mteb[beir])\n  Downloading beir-2.0.0.tar.gz (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.2.0->mteb[beir]) (6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb[beir]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb[beir]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb[beir]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->mteb[beir]) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb[beir]) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb[beir]) (3.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb[beir]) (4.30.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb[beir]) (0.15.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb[beir]) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.0->mteb[beir]) (0.1.99)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mteb[beir]) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->mteb[beir]) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mteb[beir]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mteb[beir]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mteb[beir]) (3.1.2)\nCollecting pytrec_eval (from beir->mteb[beir])\n  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting faiss_cpu (from beir->mteb[beir])\n  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting elasticsearch==7.9.1 (from beir->mteb[beir])\n  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->mteb[beir]) (23.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mteb[beir]) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mteb[beir]) (2.15.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb[beir]) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb[beir]) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb[beir]) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb[beir]) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.2.0->mteb[beir]) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mteb[beir]) (0.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.2.0->mteb[beir]) (3.0.9)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb[beir]) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb[beir]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb[beir]) (0.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mteb[beir]) (2.1.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.0->mteb[beir]) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.2.0->mteb[beir]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.2.0->mteb[beir]) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mteb[beir]) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.0->mteb[beir]) (9.5.0)\nBuilding wheels for collected packages: beir, pytrec_eval\n  Building wheel for beir (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63570 sha256=b9e641900652a88336ba4cc30ed3f53187c86ec86af23f6242382be26cde6565\n  Stored in directory: /root/.cache/pip/wheels/1c/14/96/c606ede3c10e9300ef771a6183af09d389459195ff5f854862\n  Building wheel for pytrec_eval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308136 sha256=1d54c9b1e6c07d483f55310eacb136fe61896eb67e3f1ec9d6fc3be3638c8fa9\n  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\nSuccessfully built beir pytrec_eval\nInstalling collected packages: faiss_cpu, pytrec_eval, elasticsearch, beir\nSuccessfully installed beir-2.0.0 elasticsearch-7.9.1 faiss_cpu-1.7.4 pytrec_eval-0.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom mteb.evaluation.evaluators import ClusteringEvaluator\nfrom mteb.evaluation import MTEB\nfrom mteb.abstasks import AbsTaskRetrieval\n\ndata = df.Description","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:54:01.796116Z","iopub.execute_input":"2023-08-02T13:54:01.796512Z","iopub.status.idle":"2023-08-02T13:54:05.454303Z","shell.execute_reply.started":"2023-08-02T13:54:01.796472Z","shell.execute_reply":"2023-08-02T13:54:05.453119Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# def preprocess_text(text):\n#     text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n#     text = ' '.join(text.split())\n#     doc = nlp(text)\n#     sentences = [i.text.strip() for i in doc.sents if len(i) > 1]\n#     return sentences\n\n# # Define custom model class\n# class MyModel():\n#     def encode(self, data, **kwargs):\n#         tf.compat.v1.reset_default_graph()\n#         tf.compat.v1.disable_eager_execution()\n\n#         url = \"https://tfhub.dev/google/elmo/3\"\n#         embed = hub.Module(url)\n\n#         sentences = []\n#         for text in data:\n#             preprocessed_sentences = preprocess_text(text)\n#             sentences.extend(preprocessed_sentences)\n\n#         embeddings = embed(\n#             sentences,\n#             signature=\"default\",\n#             as_dict=True)[\"default\"]\n\n#         with tf.compat.v1.Session() as sess:\n#             sess.run(tf.compat.v1.global_variables_initializer())\n#             sess.run(tf.compat.v1.tables_initializer())\n#             x = sess.run(embeddings)\n\n#         return x\n\n# # Instantiate your model\n# model = MyModel()\n\n# # Instantiate the MTEB framework\n# evaluation = MTEB(tasks=[\"TwentyNewsgroupsClustering\"])\n\n# # Run the evaluation\n# evaluation.run(model, output_folder=\"results/elmo\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n    text = ' '.join(text.split())\n    doc = nlp(text)\n    sentences = [i.text.strip() for i in doc.sents if len(i) > 1]\n    return sentences\n\nclass MyModel():\n    def encode(self, data, **kwargs):\n        url = \"https://tfhub.dev/google/elmo/3\"\n        embed = hub.load(url)\n\n        sentences = []\n        for text in data:\n            preprocessed_sentences = preprocess_text(text)\n            sentences.extend(preprocessed_sentences)\n\n        with tf.Graph().as_default():\n            text_input = tf.placeholder(dtype=tf.string, shape=[None])\n            embeddings = embed(text_input)\n            \n            with tf.compat.v1.Session() as sess:\n                sess.run(tf.compat.v1.global_variables_initializer())\n                sess.run(tf.compat.v1.tables_initializer())\n                x = sess.run(embeddings, feed_dict={text_input: sentences})\n        \n        return x\n\n# Instantiate your model\nmodel = MyModel()\n\n# Instantiate the MTEB framework\nevaluation = MTEB(tasks=[\"HotpotQA\"])\n\n# Run the evaluation\nevaluation.run(model, output_folder=\"results/elmo\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:40:50.743958Z","iopub.execute_input":"2023-08-02T13:40:50.744433Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mRetrieval\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    - HotpotQA, \u001b[3;33mbeir\u001b[0m, \u001b[3;38;5;241ms2p\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - HotpotQA, <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">beir</span>, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5233329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df53df25aec4097ac60db19fff732c7"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n    text = ' '.join(text.split())\n    doc = nlp(text)\n    sentences = [i.text.strip() for i in doc.sents if len(i) > 1]\n    return sentences\n\n# Define custom model class\nclass MyModel():\n    def encode(self, data, **kwargs):\n        tf.compat.v1.reset_default_graph()\n        tf.compat.v1.disable_eager_execution()\n\n        url = \"https://tfhub.dev/google/elmo/3\"\n        embed = hub.Module(url)\n\n        sentences = []\n        for text in data:\n            preprocessed_sentences = preprocess_text(text)\n            sentences.extend(preprocessed_sentences)\n\n        # Reduce batch size and disable GPU usage\n        with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count={'GPU': 0})) as sess:\n            sess.run(tf.compat.v1.global_variables_initializer())\n            sess.run(tf.compat.v1.tables_initializer())\n            x = sess.run(embed)\n\n        return x\n    \nmodel = MyModel()\n\n# Instantiate the MTEB framework\nevaluation = MTEB(tasks=[\"ArguAna\"])\nevaluation.run(model, output_folder=f\"results/elmo\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:54:05.455705Z","iopub.execute_input":"2023-08-02T13:54:05.456577Z","iopub.status.idle":"2023-08-02T13:55:19.754489Z","shell.execute_reply.started":"2023-08-02T13:54:05.456536Z","shell.execute_reply":"2023-08-02T13:55:19.752876Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mRetrieval\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    - ArguAna, \u001b[3;33mbeir\u001b[0m, \u001b[3;38;5;241mp2p\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - ArguAna, <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">beir</span>, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">p2p</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/root/.cache/huggingface/datasets/BeIR/arguana.zip:   0%|          | 0.00/3.60M [00:00<?, ?iB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f63ff90d6e4833aadd482dfa2147db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8674 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261feb048dd94f7eafa915420cc2ca59"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:304\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_fetches\u001b[38;5;241m.\u001b[39mappend(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:4012\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4011\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 4012\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:4100\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4099\u001b[0m   \u001b[38;5;66;03m# We give up!\u001b[39;00m\n\u001b[0;32m-> 4100\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not convert a \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m into a \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   4101\u001b[0m                   (\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, types_str))\n","\u001b[0;31mTypeError\u001b[0m: Can not convert a Module into a Tensor or Operation.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Instantiate the MTEB framework\u001b[39;00m\n\u001b[1;32m     33\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m MTEB(tasks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguAna\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/elmo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mteb/evaluation/MTEB.py:271\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mdescription[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    272\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check all the error logs at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mteb/evaluation/MTEB.py:253\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m task_eval_splits:\n\u001b[1;32m    252\u001b[0m     tick \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 253\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     tock \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    255\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mdescription[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtock\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtick\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py:101\u001b[0m, in \u001b[0;36mAbsTaskRetrieval.evaluate\u001b[0;34m(self, model, split, batch_size, corpus_chunk_size, target_devices, score_function, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m retriever \u001b[38;5;241m=\u001b[39m EvaluateRetrieval(model, score_function\u001b[38;5;241m=\u001b[39mscore_function)  \u001b[38;5;66;03m# or \"cos_sim\" or \"dot\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 101\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken to retrieve: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end_time \u001b[38;5;241m-\u001b[39m start_time))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/beir/retrieval/evaluation.py:20\u001b[0m, in \u001b[0;36mEvaluateRetrieval.retrieve\u001b[0;34m(self, corpus, queries, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel/Technique has not been provided!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/beir/retrieval/search/dense/exact_search.py:42\u001b[0m, in \u001b[0;36mDenseRetrievalExactSearch.search\u001b[0;34m(self, corpus, queries, top_k, score_function, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m {qid: {} \u001b[38;5;28;01mfor\u001b[39;00m qid \u001b[38;5;129;01min\u001b[39;00m query_ids}\n\u001b[1;32m     41\u001b[0m queries \u001b[38;5;241m=\u001b[39m [queries[qid] \u001b[38;5;28;01mfor\u001b[39;00m qid \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[0;32m---> 42\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_queries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorting Corpus by document length (Longest first)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m corpus_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(corpus, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;28mlen\u001b[39m(corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mteb/abstasks/AbsTaskRetrieval.py:154\u001b[0m, in \u001b[0;36mDRESModel.encode_queries\u001b[0;34m(self, queries, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_queries\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries: List[\u001b[38;5;28mstr\u001b[39m], batch_size: \u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36mMyModel.encode\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglobal_variables_initializer())\n\u001b[1;32m     25\u001b[0m     sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtables_initializer())\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1176\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       feed_map[compat\u001b[38;5;241m.\u001b[39mas_bytes(subfeed_t\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m (subfeed_t, subfeed_val)\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;66;03m# Create a fetch handler to take care of the structure of fetches.\u001b[39;00m\n\u001b[0;32m-> 1176\u001b[0m fetch_handler \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_handles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_handles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;66;03m# Run request and get response.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;66;03m# We need to keep the returned movers alive for the following _do_run().\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;66;03m# These movers are no longer needed when _do_run() completes, and\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;66;03m# of a handle from a different device as an error.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_with_movers(feed_dict_tensor, feed_map)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:485\u001b[0m, in \u001b[0;36m_FetchHandler.__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a fetch handler.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    direct feeds.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 485\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_mapper \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchMapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targets \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:276\u001b[0m, in \u001b[0;36m_FetchMapper.for_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fetch, tensor_type):\n\u001b[1;32m    275\u001b[0m       fetches, contraction_fn \u001b[38;5;241m=\u001b[39m fetch_fn(fetch)\n\u001b[0;32m--> 276\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ElementFetchMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontraction_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Did not find anything.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    279\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:307\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_fetches\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mas_graph_element(\n\u001b[1;32m    305\u001b[0m       fetch, allow_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    308\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m must be a string or Tensor. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    309\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be interpreted as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    312\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Tensor. (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Argument `fetch` = <tensorflow_hub.module.Module object at 0x7c9daabace80> has invalid type \"Module\" must be a string or Tensor. (Can not convert a Module into a Tensor or Operation.)"],"ename":"TypeError","evalue":"Argument `fetch` = <tensorflow_hub.module.Module object at 0x7c9daabace80> has invalid type \"Module\" must be a string or Tensor. (Can not convert a Module into a Tensor or Operation.)","output_type":"error"}]}]}